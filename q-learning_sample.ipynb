{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Episode finished after 28.000000 time steps / mean 0.000000\n",
      "1 Episode finished after 35.000000 time steps / mean -1.730000\n",
      "2 Episode finished after 21.000000 time steps / mean -3.390000\n",
      "3 Episode finished after 13.000000 time steps / mean -5.190000\n",
      "4 Episode finished after 21.000000 time steps / mean -7.070000\n",
      "5 Episode finished after 10.000000 time steps / mean -8.870000\n",
      "6 Episode finished after 153.000000 time steps / mean -10.780000\n",
      "7 Episode finished after 29.000000 time steps / mean -11.260000\n",
      "8 Episode finished after 101.000000 time steps / mean -12.980000\n",
      "9 Episode finished after 97.000000 time steps / mean -13.980000\n",
      "10 Episode finished after 9.000000 time steps / mean -15.020000\n",
      "11 Episode finished after 10.000000 time steps / mean -16.940000\n",
      "12 Episode finished after 11.000000 time steps / mean -18.850000\n",
      "13 Episode finished after 8.000000 time steps / mean -20.750000\n",
      "14 Episode finished after 63.000000 time steps / mean -22.680000\n",
      "15 Episode finished after 100.000000 time steps / mean -24.060000\n",
      "16 Episode finished after 139.000000 time steps / mean -25.070000\n",
      "17 Episode finished after 35.000000 time steps / mean -25.690000\n",
      "18 Episode finished after 10.000000 time steps / mean -27.350000\n",
      "19 Episode finished after 97.000000 time steps / mean -29.260000\n",
      "20 Episode finished after 17.000000 time steps / mean -30.300000\n",
      "21 Episode finished after 69.000000 time steps / mean -32.140000\n",
      "22 Episode finished after 42.000000 time steps / mean -33.460000\n",
      "23 Episode finished after 93.000000 time steps / mean -35.050000\n",
      "24 Episode finished after 53.000000 time steps / mean -36.130000\n",
      "25 Episode finished after 95.000000 time steps / mean -37.610000\n",
      "26 Episode finished after 41.000000 time steps / mean -38.670000\n",
      "27 Episode finished after 11.000000 time steps / mean -40.270000\n",
      "28 Episode finished after 40.000000 time steps / mean -42.170000\n",
      "29 Episode finished after 64.000000 time steps / mean -43.780000\n",
      "30 Episode finished after 52.000000 time steps / mean -45.150000\n",
      "31 Episode finished after 61.000000 time steps / mean -46.640000\n",
      "32 Episode finished after 44.000000 time steps / mean -48.040000\n",
      "33 Episode finished after 33.000000 time steps / mean -49.610000\n",
      "34 Episode finished after 72.000000 time steps / mean -51.290000\n",
      "35 Episode finished after 31.000000 time steps / mean -52.580000\n",
      "36 Episode finished after 60.000000 time steps / mean -54.280000\n",
      "37 Episode finished after 31.000000 time steps / mean -55.690000\n",
      "38 Episode finished after 76.000000 time steps / mean -57.390000\n",
      "39 Episode finished after 83.000000 time steps / mean -58.640000\n",
      "40 Episode finished after 39.000000 time steps / mean -59.820000\n",
      "41 Episode finished after 58.000000 time steps / mean -61.440000\n",
      "42 Episode finished after 27.000000 time steps / mean -62.870000\n",
      "43 Episode finished after 144.000000 time steps / mean -64.610000\n",
      "44 Episode finished after 158.000000 time steps / mean -65.180000\n",
      "45 Episode finished after 40.000000 time steps / mean -65.610000\n",
      "46 Episode finished after 200.000000 time steps / mean -67.220000\n",
      "47 Episode finished after 200.000000 time steps / mean -65.220000\n",
      "48 Episode finished after 133.000000 time steps / mean -63.220000\n",
      "49 Episode finished after 43.000000 time steps / mean -63.900000\n",
      "50 Episode finished after 46.000000 time steps / mean -65.480000\n",
      "51 Episode finished after 183.000000 time steps / mean -67.030000\n",
      "52 Episode finished after 164.000000 time steps / mean -67.210000\n",
      "53 Episode finished after 161.000000 time steps / mean -67.580000\n",
      "54 Episode finished after 148.000000 time steps / mean -67.980000\n",
      "55 Episode finished after 162.000000 time steps / mean -68.510000\n",
      "56 Episode finished after 53.000000 time steps / mean -68.900000\n",
      "57 Episode finished after 60.000000 time steps / mean -70.380000\n",
      "58 Episode finished after 103.000000 time steps / mean -71.790000\n",
      "59 Episode finished after 179.000000 time steps / mean -72.770000\n",
      "60 Episode finished after 156.000000 time steps / mean -72.990000\n",
      "61 Episode finished after 182.000000 time steps / mean -73.440000\n",
      "62 Episode finished after 110.000000 time steps / mean -73.630000\n",
      "63 Episode finished after 122.000000 time steps / mean -74.540000\n",
      "64 Episode finished after 113.000000 time steps / mean -75.330000\n",
      "65 Episode finished after 156.000000 time steps / mean -76.210000\n",
      "66 Episode finished after 200.000000 time steps / mean -76.660000\n",
      "67 Episode finished after 167.000000 time steps / mean -74.660000\n",
      "68 Episode finished after 167.000000 time steps / mean -75.000000\n",
      "69 Episode finished after 127.000000 time steps / mean -75.340000\n",
      "70 Episode finished after 89.000000 time steps / mean -76.080000\n",
      "71 Episode finished after 200.000000 time steps / mean -77.200000\n",
      "72 Episode finished after 130.000000 time steps / mean -75.200000\n",
      "73 Episode finished after 15.000000 time steps / mean -75.910000\n",
      "74 Episode finished after 74.000000 time steps / mean -77.770000\n",
      "75 Episode finished after 200.000000 time steps / mean -79.040000\n",
      "76 Episode finished after 120.000000 time steps / mean -77.040000\n",
      "77 Episode finished after 200.000000 time steps / mean -77.850000\n",
      "78 Episode finished after 188.000000 time steps / mean -75.850000\n",
      "79 Episode finished after 200.000000 time steps / mean -75.980000\n",
      "80 Episode finished after 182.000000 time steps / mean -73.980000\n",
      "81 Episode finished after 200.000000 time steps / mean -74.170000\n",
      "82 Episode finished after 170.000000 time steps / mean -72.170000\n",
      "83 Episode finished after 122.000000 time steps / mean -72.480000\n",
      "84 Episode finished after 54.000000 time steps / mean -73.270000\n",
      "85 Episode finished after 200.000000 time steps / mean -74.740000\n",
      "86 Episode finished after 193.000000 time steps / mean -72.740000\n",
      "87 Episode finished after 200.000000 time steps / mean -72.820000\n",
      "88 Episode finished after 200.000000 time steps / mean -70.820000\n",
      "89 Episode finished after 184.000000 time steps / mean -68.820000\n",
      "90 Episode finished after 159.000000 time steps / mean -68.990000\n",
      "91 Episode finished after 173.000000 time steps / mean -69.410000\n",
      "92 Episode finished after 200.000000 time steps / mean -69.690000\n",
      "93 Episode finished after 200.000000 time steps / mean -67.690000\n",
      "94 Episode finished after 175.000000 time steps / mean -65.690000\n",
      "95 Episode finished after 200.000000 time steps / mean -65.950000\n",
      "96 Episode finished after 200.000000 time steps / mean -63.950000\n",
      "97 Episode finished after 132.000000 time steps / mean -61.950000\n",
      "98 Episode finished after 200.000000 time steps / mean -62.640000\n",
      "99 Episode finished after 190.000000 time steps / mean -60.640000\n",
      "100 Episode finished after 185.000000 time steps / mean -60.750000\n",
      "101 Episode finished after 58.000000 time steps / mean -59.180000\n",
      "102 Episode finished after 200.000000 time steps / mean -58.950000\n",
      "103 Episode finished after 200.000000 time steps / mean -55.150000\n",
      "104 Episode finished after 147.000000 time steps / mean -51.270000\n",
      "105 Episode finished after 154.000000 time steps / mean -50.010000\n",
      "106 Episode finished after 169.000000 time steps / mean -48.570000\n",
      "107 Episode finished after 178.000000 time steps / mean -48.410000\n",
      "108 Episode finished after 200.000000 time steps / mean -46.920000\n",
      "109 Episode finished after 200.000000 time steps / mean -43.920000\n",
      "110 Episode finished after 166.000000 time steps / mean -40.880000\n",
      "111 Episode finished after 114.000000 time steps / mean -39.310000\n",
      "112 Episode finished after 166.000000 time steps / mean -38.270000\n",
      "113 Episode finished after 200.000000 time steps / mean -36.720000\n",
      "114 Episode finished after 119.000000 time steps / mean -32.790000\n",
      "115 Episode finished after 195.000000 time steps / mean -32.230000\n",
      "116 Episode finished after 166.000000 time steps / mean -31.280000\n",
      "117 Episode finished after 194.000000 time steps / mean -31.010000\n",
      "118 Episode finished after 200.000000 time steps / mean -29.420000\n",
      "119 Episode finished after 146.000000 time steps / mean -25.510000\n",
      "120 Episode finished after 200.000000 time steps / mean -25.020000\n",
      "121 Episode finished after 200.000000 time steps / mean -21.180000\n",
      "122 Episode finished after 200.000000 time steps / mean -17.860000\n",
      "123 Episode finished after 200.000000 time steps / mean -14.270000\n",
      "124 Episode finished after 200.000000 time steps / mean -11.190000\n",
      "125 Episode finished after 160.000000 time steps / mean -7.710000\n",
      "126 Episode finished after 93.000000 time steps / mean -7.060000\n",
      "127 Episode finished after 139.000000 time steps / mean -6.540000\n",
      "128 Episode finished after 186.000000 time steps / mean -5.260000\n",
      "129 Episode finished after 160.000000 time steps / mean -3.800000\n",
      "130 Episode finished after 200.000000 time steps / mean -2.840000\n",
      "131 Episode finished after 107.000000 time steps / mean 0.650000\n",
      "132 Episode finished after 181.000000 time steps / mean 1.110000\n",
      "133 Episode finished after 192.000000 time steps / mean 2.480000\n",
      "134 Episode finished after 200.000000 time steps / mean 4.070000\n",
      "135 Episode finished after 200.000000 time steps / mean 7.360000\n",
      "136 Episode finished after 112.000000 time steps / mean 11.060000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137 Episode finished after 174.000000 time steps / mean 11.580000\n",
      "138 Episode finished after 194.000000 time steps / mean 13.010000\n",
      "139 Episode finished after 200.000000 time steps / mean 14.190000\n",
      "140 Episode finished after 193.000000 time steps / mean 17.370000\n",
      "141 Episode finished after 200.000000 time steps / mean 18.910000\n",
      "142 Episode finished after 200.000000 time steps / mean 22.340000\n",
      "143 Episode finished after 200.000000 time steps / mean 26.080000\n",
      "144 Episode finished after 200.000000 time steps / mean 28.650000\n",
      "145 Episode finished after 153.000000 time steps / mean 31.080000\n",
      "146 Episode finished after 200.000000 time steps / mean 32.210000\n",
      "147 Episode finished after 182.000000 time steps / mean 32.210000\n",
      "148 Episode finished after 200.000000 time steps / mean 30.020000\n",
      "149 Episode finished after 173.000000 time steps / mean 32.700000\n",
      "150 Episode finished after 146.000000 time steps / mean 34.000000\n",
      "151 Episode finished after 194.000000 time steps / mean 35.000000\n",
      "152 Episode finished after 149.000000 time steps / mean 35.110000\n",
      "153 Episode finished after 146.000000 time steps / mean 34.960000\n",
      "154 Episode finished after 173.000000 time steps / mean 34.810000\n",
      "155 Episode finished after 172.000000 time steps / mean 35.060000\n",
      "156 Episode finished after 120.000000 time steps / mean 35.160000\n",
      "157 Episode finished after 33.000000 time steps / mean 35.830000\n",
      "158 Episode finished after 200.000000 time steps / mean 35.560000\n",
      "159 Episode finished after 147.000000 time steps / mean 38.540000\n",
      "160 Episode finished after 124.000000 time steps / mean 38.220000\n",
      "161 Episode finished after 20.000000 time steps / mean 37.900000\n",
      "162 Episode finished after 99.000000 time steps / mean 36.280000\n",
      "163 Episode finished after 200.000000 time steps / mean 36.170000\n",
      "164 Episode finished after 19.000000 time steps / mean 38.960000\n",
      "165 Episode finished after 23.000000 time steps / mean 38.020000\n",
      "166 Episode finished after 137.000000 time steps / mean 36.690000\n",
      "167 Episode finished after 140.000000 time steps / mean 34.050000\n",
      "168 Episode finished after 111.000000 time steps / mean 33.780000\n",
      "169 Episode finished after 99.000000 time steps / mean 33.220000\n",
      "170 Episode finished after 122.000000 time steps / mean 32.940000\n",
      "171 Episode finished after 94.000000 time steps / mean 33.270000\n",
      "172 Episode finished after 113.000000 time steps / mean 30.200000\n",
      "173 Episode finished after 186.000000 time steps / mean 30.030000\n",
      "174 Episode finished after 200.000000 time steps / mean 31.740000\n",
      "175 Episode finished after 146.000000 time steps / mean 35.010000\n",
      "176 Episode finished after 200.000000 time steps / mean 32.460000\n",
      "177 Episode finished after 189.000000 time steps / mean 35.270000\n",
      "178 Episode finished after 168.000000 time steps / mean 33.150000\n",
      "179 Episode finished after 118.000000 time steps / mean 32.950000\n",
      "180 Episode finished after 174.000000 time steps / mean 30.120000\n",
      "181 Episode finished after 138.000000 time steps / mean 30.040000\n",
      "182 Episode finished after 183.000000 time steps / mean 27.410000\n",
      "183 Episode finished after 200.000000 time steps / mean 27.540000\n",
      "184 Episode finished after 147.000000 time steps / mean 30.330000\n",
      "185 Episode finished after 200.000000 time steps / mean 31.260000\n",
      "186 Episode finished after 155.000000 time steps / mean 31.260000\n",
      "187 Episode finished after 200.000000 time steps / mean 30.880000\n",
      "188 Episode finished after 168.000000 time steps / mean 30.880000\n",
      "189 Episode finished after 200.000000 time steps / mean 28.550000\n",
      "190 Episode finished after 200.000000 time steps / mean 30.720000\n",
      "191 Episode finished after 200.000000 time steps / mean 33.140000\n",
      "192 Episode finished after 92.000000 time steps / mean 35.420000\n",
      "193 Episode finished after 131.000000 time steps / mean 32.330000\n",
      "194 Episode finished after 23.000000 time steps / mean 29.630000\n",
      "195 Episode finished after 176.000000 time steps / mean 28.110000\n",
      "196 Episode finished after 200.000000 time steps / mean 25.860000\n",
      "197 Episode finished after 200.000000 time steps / mean 25.860000\n",
      "198 Episode finished after 200.000000 time steps / mean 28.550000\n",
      "199 Episode finished after 200.000000 time steps / mean 28.550000\n",
      "200 Episode finished after 200.000000 time steps / mean 30.660000\n",
      "201 Episode finished after 200.000000 time steps / mean 32.820000\n",
      "202 Episode finished after 200.000000 time steps / mean 36.250000\n",
      "203 Episode finished after 200.000000 time steps / mean 36.250000\n",
      "204 Episode finished after 200.000000 time steps / mean 36.250000\n",
      "205 Episode finished after 200.000000 time steps / mean 38.790000\n",
      "206 Episode finished after 200.000000 time steps / mean 41.260000\n",
      "207 Episode finished after 200.000000 time steps / mean 43.580000\n",
      "208 Episode finished after 200.000000 time steps / mean 45.810000\n",
      "209 Episode finished after 200.000000 time steps / mean 45.810000\n",
      "210 Episode finished after 200.000000 time steps / mean 45.810000\n",
      "211 Episode finished after 200.000000 time steps / mean 48.160000\n",
      "212 Episode finished after 200.000000 time steps / mean 51.030000\n",
      "213 Episode finished after 183.000000 time steps / mean 53.380000\n",
      "214 Episode finished after 200.000000 time steps / mean 51.200000\n",
      "215 Episode finished after 200.000000 time steps / mean 54.020000\n",
      "216 Episode finished after 200.000000 time steps / mean 56.080000\n",
      "217 Episode finished after 200.000000 time steps / mean 58.430000\n",
      "218 Episode finished after 200.000000 time steps / mean 60.500000\n",
      "219 Episode finished after 200.000000 time steps / mean 60.500000\n",
      "220 Episode finished after 200.000000 time steps / mean 63.050000\n",
      "221 Episode finished after 200.000000 time steps / mean 63.050000\n",
      "222 Episode finished after 200.000000 time steps / mean 63.050000\n",
      "223 Episode finished after 200.000000 time steps / mean 63.050000\n",
      "224 Episode finished after 200.000000 time steps / mean 63.050000\n",
      "225 Episode finished after 200.000000 time steps / mean 63.050000\n",
      "226 Episode finished after 200.000000 time steps / mean 65.460000\n",
      "227 Episode finished after 200.000000 time steps / mean 68.540000\n",
      "228 Episode finished after 200.000000 time steps / mean 71.160000\n",
      "229 Episode finished after 200.000000 time steps / mean 73.310000\n",
      "230 Episode finished after 200.000000 time steps / mean 75.720000\n",
      "231 Episode finished after 200.000000 time steps / mean 75.720000\n",
      "232 Episode finished after 200.000000 time steps / mean 78.660000\n",
      "233 Episode finished after 200.000000 time steps / mean 80.860000\n",
      "234 Episode finished after 200.000000 time steps / mean 82.950000\n",
      "235 Episode finished after 200.000000 time steps / mean 82.950000\n",
      "236 Episode finished after 200.000000 time steps / mean 82.950000\n",
      "237 Episode finished after 200.000000 time steps / mean 85.840000\n",
      "238 Episode finished after 200.000000 time steps / mean 88.110000\n",
      "239 Episode finished after 200.000000 time steps / mean 90.180000\n",
      "240 Episode finished after 200.000000 time steps / mean 90.180000\n",
      "241 Episode finished after 200.000000 time steps / mean 92.260000\n",
      "242 Episode finished after 57.000000 time steps / mean 92.260000\n",
      "243 Episode finished after 200.000000 time steps / mean 88.820000\n",
      "244 Episode finished after 200.000000 time steps / mean 88.820000\n",
      "245 Episode finished after 200.000000 time steps / mean 88.820000\n",
      "246 Episode finished after 200.000000 time steps / mean 91.300000\n",
      "247 Episode finished after 200.000000 time steps / mean 91.300000\n",
      "248 Episode finished after 200.000000 time steps / mean 93.490000\n",
      "249 Episode finished after 200.000000 time steps / mean 93.490000\n",
      "250 Episode finished after 200.000000 time steps / mean 95.770000\n",
      "251 Episode finished after 200.000000 time steps / mean 98.320000\n",
      "252 Episode finished after 200.000000 time steps / mean 100.390000\n",
      "253 Episode finished after 200.000000 time steps / mean 102.910000\n",
      "254 Episode finished after 200.000000 time steps / mean 105.460000\n",
      "255 Episode finished after 200.000000 time steps / mean 107.740000\n",
      "256 Episode finished after 200.000000 time steps / mean 110.030000\n",
      "257 Episode finished after 200.000000 time steps / mean 112.840000\n",
      "258 Episode finished after 200.000000 time steps / mean 116.520000\n",
      "259 Episode finished after 200.000000 time steps / mean 116.520000\n",
      "260 Episode finished after 200.000000 time steps / mean 119.060000\n",
      "261 Episode finished after 200.000000 time steps / mean 121.830000\n",
      "262 Episode finished after 200.000000 time steps / mean 125.640000\n",
      "263 Episode finished after 200.000000 time steps / mean 128.660000\n",
      "264 Episode finished after 200.000000 time steps / mean 128.660000\n",
      "265 Episode finished after 200.000000 time steps / mean 132.480000\n",
      "266 Episode finished after 200.000000 time steps / mean 136.260000\n",
      "267 Episode finished after 200.000000 time steps / mean 138.900000\n",
      "268 Episode finished after 200.000000 time steps / mean 141.510000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269 Episode finished after 200.000000 time steps / mean 144.410000\n",
      "270 Episode finished after 200.000000 time steps / mean 147.430000\n",
      "271 Episode finished after 200.000000 time steps / mean 150.220000\n",
      "272 Episode finished after 200.000000 time steps / mean 153.290000\n",
      "273 Episode finished after 200.000000 time steps / mean 156.170000\n",
      "274 Episode finished after 200.000000 time steps / mean 158.320000\n",
      "275 Episode finished after 200.000000 time steps / mean 158.320000\n",
      "276 Episode finished after 200.000000 time steps / mean 160.870000\n",
      "277 Episode finished after 200.000000 time steps / mean 160.870000\n",
      "278 Episode finished after 200.000000 time steps / mean 162.990000\n",
      "279 Episode finished after 200.000000 time steps / mean 165.320000\n",
      "280 Episode finished after 200.000000 time steps / mean 168.150000\n",
      "281 Episode finished after 200.000000 time steps / mean 170.420000\n",
      "282 Episode finished after 200.000000 time steps / mean 173.050000\n",
      "283 Episode finished after 200.000000 time steps / mean 175.230000\n",
      "284 Episode finished after 200.000000 time steps / mean 175.230000\n",
      "285 Episode finished after 200.000000 time steps / mean 177.770000\n",
      "286 Episode finished after 200.000000 time steps / mean 177.770000\n",
      "287 Episode finished after 200.000000 time steps / mean 180.230000\n",
      "288 Episode finished after 200.000000 time steps / mean 180.230000\n",
      "289 Episode finished after 200.000000 time steps / mean 182.560000\n",
      "290 Episode finished after 200.000000 time steps / mean 182.560000\n",
      "291 Episode finished after 200.000000 time steps / mean 182.560000\n",
      "292 Episode finished after 200.000000 time steps / mean 182.560000\n",
      "293 Episode finished after 200.000000 time steps / mean 185.650000\n",
      "294 Episode finished after 200.000000 time steps / mean 188.350000\n",
      "295 Episode finished after 200.000000 time steps / mean 192.130000\n",
      "296 Episode finished after 200.000000 time steps / mean 194.380000\n",
      "297 Episode finished after 200.000000 time steps / mean 194.380000\n",
      "298 Episode finished after 200.000000 time steps / mean 194.380000\n",
      "299 Episode finished after 200.000000 time steps / mean 194.380000\n",
      "300 Episode finished after 200.000000 time steps / mean 194.380000\n",
      "301 Episode finished after 200.000000 time steps / mean 194.380000\n",
      "302 Episode finished after 200.000000 time steps / mean 194.380000\n",
      "303 Episode finished after 200.000000 time steps / mean 194.380000\n",
      "304 Episode finished after 200.000000 time steps / mean 194.380000\n",
      "305 Episode finished after 200.000000 time steps / mean 194.380000\n",
      "306 Episode finished after 200.000000 time steps / mean 194.380000\n",
      "307 Episode finished after 200.000000 time steps / mean 194.380000\n",
      "308 Episode finished after 200.000000 time steps / mean 194.380000\n",
      "309 Episode finished after 200.000000 time steps / mean 194.380000\n",
      "310 Episode finished after 200.000000 time steps / mean 194.380000\n",
      "311 Episode finished after 200.000000 time steps / mean 194.380000\n",
      "312 Episode finished after 200.000000 time steps / mean 194.380000\n",
      "313 Episode finished after 200.000000 time steps / mean 194.380000\n",
      "Episode 313 train agent successfuly!\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "abstract",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-86a836d66296>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_STEPS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# １試行のループ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_learned\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# 学習が終了したらcartPoleを描画する\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                 \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#カートのx位置を出力\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/gym/envs/classic_control/cartpole.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassic_control\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mViewer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreen_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m             \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcartwidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcartwidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcartheight\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcartheight\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0maxleoffset\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mcartheight\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m4.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/gym/envs/classic_control/rendering.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, width, height, display)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWindow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow_closed_by_user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misopen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/pyglet/window/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, width, height, caption, resizable, style, fullscreen, visible, vsync, display, screen, config, context, mode)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mscreen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_screen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/pyglet/canvas/base.py\u001b[0m in \u001b[0;36mget_default_screen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mScreen\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         '''\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_screens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_windows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/pyglet/canvas/base.py\u001b[0m in \u001b[0;36mget_screens\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mScreen\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         '''\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'abstract'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_default_screen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: abstract"
     ]
    }
   ],
   "source": [
    "# coding:utf-8\n",
    "import gym  #倒立振子(cartpole)の実行環境\n",
    "from gym import wrappers  #gymの画像保存\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def make_bins(clip_min, clip_max, num):\n",
    "    \"\"\"\n",
    "    関数の概要：digitize_stateで離散値のindexに直すための区切りを作成する。\n",
    "    @param clip_min：最小値\n",
    "    @param clip_max：最大値\n",
    "    @param num     ：digitize_stateで分割したい数\n",
    "\n",
    "    np.linspace で num+1この区切りを作成する\n",
    "    →[1:-1]とスライスするので区切りの数は (num+1)-2 = num-1\n",
    "    →間の数は(num-1)-1 = num-2、区切りの外側が2つあるので、(num-2)+2 = num となり、結局num個に分割可能。\n",
    "    \"\"\"\n",
    "    return np.linspace(clip_min, clip_max, num + 1)[1:-1]\n",
    "def digitize_state(observation):\n",
    "    \"\"\"\n",
    "    関数の概要：各値を離散値のラベルに変換し、状態をQ-Tableでのindexで表す。\n",
    "    　　　　　　なお、N進数でindexを表していると考えればsumの部分が理解しやすい。\n",
    "    @param observation：観測値（x,v,θ,ω）\n",
    "    @return index     ：Q-Tableのindex\n",
    "\n",
    "    【np.digitizeの説明】\n",
    "    x    = np.array([-0.5, 0, 0.5, 1, 1.5, 2, 2.5])\n",
    "    bins = np.array([0,1,2])\n",
    "    np.digitize(x, bins)\n",
    "    >>> array([0, 1, 1, 2, 2, 3, 3])\n",
    "    \"\"\"\n",
    "    x, v, theta, omega = observation\n",
    "    digitized = [\n",
    "        np.digitize(x,     bins=make_bins(-2.4, 2.4, N_DIZITIZED)),\n",
    "        np.digitize(v,     bins=make_bins(-3.0, 3.0, N_DIZITIZED)),\n",
    "        np.digitize(theta, bins=make_bins(-0.5, 0.5, N_DIZITIZED)),\n",
    "        np.digitize(omega, bins=make_bins(-2.0, 2.0, N_DIZITIZED))\n",
    "    ]\n",
    "    index = sum([val * (N_DIZITIZED**i) for i, val in enumerate(digitized)])\n",
    "    return index\n",
    "def get_action(next_state, episode):\n",
    "    \"\"\"\n",
    "    関数の概要：行動a(t)をε-greedy法を用いて求める。\n",
    "    　　　　　　なお、εの値を徐々に小さくすることで、最適行動を取る確率を高めている。\n",
    "    @param next_state：次の状態のQ-Tableでのindex\n",
    "    @param episode   ：試行回数。この値でεを調整する\n",
    "    \"\"\"\n",
    "    epsilon = 0.5 * (1 / (episode + 1))\n",
    "    if epsilon <= np.random.uniform(0, 1):\n",
    "        next_action = np.argmax(q_table[next_state])\n",
    "    else:\n",
    "        next_action = np.random.choice([0, 1])\n",
    "    return next_action\n",
    "def update_Qtable(q_table, state, action, reward, next_state):\n",
    "    \"\"\"\n",
    "    関数の概要：Qテーブルを更新する。\n",
    "                next_Max_Q では、２種類の行動のうち報酬の大きいものを返す。\n",
    "    式： Q(s,a) = (1−α)Q(s,a) + α(R(s,a)+γmax E[Q(s',a')])\n",
    "    \"\"\"\n",
    "    gamma = 0.99\n",
    "    alpha = 0.5\n",
    "    next_Max_Q = max(q_table[next_state][0], q_table[next_state][1])\n",
    "    q_table[state, action] = (1-alpha) * q_table[state, action] +\\\n",
    "                              alpha     * (reward + gamma*next_Max_Q)\n",
    "    return q_table\n",
    "\n",
    "#=== パラメータの初期化 ===\n",
    "MAX_STEPS   = 200  # １回の試行の step 数\n",
    "GOAL_REWARD = 195\n",
    "N_RECENT    = 100  # 直近この数の持続step数の平均がGOAL_REWARDを超えていれば学習が終了。\n",
    "N_EPISODES  = 2000 # 総試行回数\n",
    "N_DIZITIZED = 6    # 離散化の分割数\n",
    "is_learned  = 0    # 学習が終わったフラグ\n",
    "is_render   = 0    # 描画フラグ\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "q_table = np.random.uniform( low=-1, high=1, size=(N_DIZITIZED**4, env.action_space.n) )\n",
    "total_reward_vec = np.zeros(N_RECENT) # 各試行の報酬を格納する\n",
    "final_x = np.zeros((N_EPISODES, 1))   # 学習後、各試行の t=200 でのｘの位置を格納する\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for episode in range(N_EPISODES):\n",
    "\n",
    "        #=== 環境の初期化（ゲームのリセット） ===\n",
    "        observation = env.reset() # ランダムで初期値が与えられる。\n",
    "        state  = digitize_state(observation)\n",
    "        action = np.argmax(q_table[state])\n",
    "        episode_reward = 0\n",
    "\n",
    "        for t in range(MAX_STEPS): # １試行のループ\n",
    "            if is_learned == 1:    # 学習が終了したらcartPoleを描画する\n",
    "                env.render()\n",
    "                time.sleep(0.1)\n",
    "                print (observation[0])  #カートのx位置を出力\n",
    "\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            \"\"\"\n",
    "            【報酬の計算】\n",
    "            ①倒れて終了した場合　：-200 の罰則項を足す。\n",
    "            ②倒れずに終了した場合：普段通り 1 の報酬を与える。\n",
    "            ③まだ続く場合　　　　：倒れていないので、 1 の報酬を与える。\n",
    "            この報酬 reward を episode_reward に足していくことで、\n",
    "            episode_reward が総持続時間を意味することになる。\n",
    "            \"\"\"\n",
    "            if done:\n",
    "                if t < 195:\n",
    "                    reward = -200 # ①倒れて終了した場合\n",
    "                else:\n",
    "                    reward = 1 # ②倒れずに終了した場合\n",
    "            else:\n",
    "                reward = 1 # ③まだ続く場合\n",
    "            episode_reward += reward  # 報酬を追加（これが持続時間に相当）\n",
    "\n",
    "            next_state = digitize_state(observation) # indexで状態を表す。\n",
    "            q_table    = update_Qtable(q_table, state, action, reward, next_state)\n",
    "            action     = get_action(next_state, episode) # 次の行動を決定する。\n",
    "            state      = next_state # 状態を一つ進め、ループを回す。\n",
    "            if done:\n",
    "                print('%d Episode finished after %f time steps / mean %f' %\n",
    "                      (episode, t + 1, total_reward_vec.mean()))\n",
    "                total_reward_vec = np.hstack((total_reward_vec[1:], episode_reward)) # 直近の報酬を記録していく。\n",
    "                if is_learned == 1:  # 学習終わっていた場合、最終位置xを格納\n",
    "                    final_x[episode, 0] = observation[0]\n",
    "                break\n",
    "\n",
    "        if (total_reward_vec.mean() >= GOAL_REWARD):  # 直近の100エピソードが規定報酬以上であれば成功\n",
    "            print('Episode %d train agent successfuly!' % episode)\n",
    "            is_learned = 1\n",
    "            # np.savetxt('learned_Q_table.csv',q_table, delimiter=\",\") # Qtableを保存する場合\n",
    "            if is_render == 0:\n",
    "                # env = wrappers.Monitor(env, './movie/cartpole-experiment-1') # 動画を保存する場合\n",
    "                is_render = 1\n",
    "\n",
    "    if is_learned:\n",
    "        np.savetxt('final_x.csv', final_x, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
